{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nextflow\n",
    "! pip install nextflow\n",
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Structure\n",
    "\n",
    "```sh\n",
    "penguin_analysis/\n",
    "├── main.nf\n",
    "├── nextflow.config\n",
    "├── data/\n",
    "│   └── penguins.csv\n",
    "├── bin/\n",
    "│   ├── data_cleaning.py\n",
    "│   ├── species_analysis.py\n",
    "│   └── visualization.py\n",
    "└── results/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p data\n",
    "mkdir -p bin\n",
    "mkdir -p results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write `data_cleaning.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bin/data_cleaning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bin/data_cleaning.py\n",
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Clean Palmer Penguins dataset')\n",
    "    parser.add_argument('input_file', help='Input CSV file path')\n",
    "    parser.add_argument('output_file', help='Output CSV file path')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def clean_column_names(df):\n",
    "    return df.rename(columns=lambda x: x.lower().replace(' ', '_'))\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def normalize_numeric_features(df):\n",
    "    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    return df\n",
    "\n",
    "def validate_data(df):\n",
    "    # Check for valid ranges\n",
    "    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    for col in numeric_cols:\n",
    "        df = df[df[col].between(df[col].quantile(0.01), df[col].quantile(0.99))]\n",
    "    \n",
    "    # Validate species names\n",
    "    valid_species = ['Adelie', 'Gentoo', 'Chinstrap']\n",
    "    df = df[df['species'].isin(valid_species)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_derived_features(df):\n",
    "    # Add bill ratio feature\n",
    "    df['bill_ratio'] = df['bill_length_mm'] / df['bill_depth_mm']\n",
    "    \n",
    "    # Add size category\n",
    "    df['size_category'] = pd.qcut(df['body_mass_g'], q=3, labels=['small', 'medium', 'large'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Load and process data\n",
    "    df = load_data(args.input_file)\n",
    "    df = clean_column_names(df)\n",
    "    df = remove_missing_values(df)\n",
    "    df = validate_data(df)\n",
    "    df = normalize_numeric_features(df)\n",
    "    df = add_derived_features(df)\n",
    "    \n",
    "    # Save cleaned data\n",
    "    df.to_csv(args.output_file, index=False)\n",
    "    print(f\"Cleaned data saved to {args.output_file}\")\n",
    "    print(f\"Shape of cleaned dataset: {df.shape}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `species_analysis.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bin/species_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bin/species_analysis.py\n",
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Analyze penguin species')\n",
    "    parser.add_argument('input_file', help='Input CSV file path')\n",
    "    parser.add_argument('species', help='Species to analyze')\n",
    "    parser.add_argument('output_dir', help='Output directory for results')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def load_and_filter_data(file_path, species):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df[df['species'] == species]\n",
    "\n",
    "def calculate_basic_stats(df):\n",
    "    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    stats_df = df[numeric_cols].agg(['mean', 'std', 'min', 'max'])\n",
    "    return stats_df\n",
    "\n",
    "def analyze_sexual_dimorphism(df):\n",
    "    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    dimorphism_stats = {}\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        male_data = df[df['sex'] == 'male'][col]\n",
    "        female_data = df[df['sex'] == 'female'][col]\n",
    "        \n",
    "        t_stat, p_value = stats.ttest_ind(male_data, female_data)\n",
    "        effect_size = (male_data.mean() - female_data.mean()) / np.sqrt((male_data.var() + female_data.var()) / 2)\n",
    "        \n",
    "        dimorphism_stats[col] = {\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'effect_size': effect_size\n",
    "        }\n",
    "    \n",
    "    return pd.DataFrame(dimorphism_stats)\n",
    "\n",
    "def create_morphological_plots(df, output_dir, species):\n",
    "    # Distribution plots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(f'Morphological Distributions - {species}')\n",
    "    \n",
    "    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    for ax, col in zip(axes.flat, numeric_cols):\n",
    "        sns.boxplot(data=df, x='sex', y=col, ax=ax)\n",
    "        ax.set_title(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/{species}_distributions.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Correlation matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title(f'Feature Correlations - {species}')\n",
    "    plt.savefig(f'{output_dir}/{species}_correlations.png')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Load and process data\n",
    "    df = load_and_filter_data(args.input_file, args.species)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    basic_stats = calculate_basic_stats(df)\n",
    "    dimorphism_stats = analyze_sexual_dimorphism(df)\n",
    "    \n",
    "    # Generate plots\n",
    "    create_morphological_plots(df, args.output_dir, args.species)\n",
    "    \n",
    "    # Save results\n",
    "    basic_stats.to_csv(f'{args.output_dir}/{args.species}_basic_stats.csv')\n",
    "    dimorphism_stats.to_csv(f'{args.output_dir}/{args.species}_dimorphism_stats.csv')\n",
    "    \n",
    "    print(f\"Analysis completed for {args.species}\")\n",
    "    print(f\"Results saved in {args.output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write `visualization.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing bin/visualization.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bin/visualization.py\n",
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Create penguin visualizations')\n",
    "    parser.add_argument('input_file', help='Input CSV file path')\n",
    "    parser.add_argument('output_dir', help='Output directory for visualizations')\n",
    "    return parser.parse_args()\n",
    "\n",
    "def create_species_comparison(df, output_dir):\n",
    "    # Create faceted boxplots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    measurements = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    for idx, measure in enumerate(measurements, 1):\n",
    "        plt.subplot(2, 2, idx)\n",
    "        sns.boxplot(data=df, x='species', y=measure, hue='sex')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(f'{measure} by Species and Sex')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/species_comparison_boxplots.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def create_interactive_scatter(df, output_dir):\n",
    "    # Interactive scatter plot with Plotly\n",
    "    fig = px.scatter(df, \n",
    "                    x='bill_length_mm', \n",
    "                    y='bill_depth_mm',\n",
    "                    color='species',\n",
    "                    symbol='sex',\n",
    "                    size='body_mass_g',\n",
    "                    hover_data=['flipper_length_mm'],\n",
    "                    title='Bill Measurements by Species')\n",
    "    \n",
    "    fig.write_html(f'{output_dir}/interactive_scatter.html')\n",
    "\n",
    "def create_correlation_heatmap(df, output_dir):\n",
    "    # Correlation heatmap\n",
    "    numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    corr = df[numeric_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Correlation Matrix of Penguin Measurements')\n",
    "    plt.savefig(f'{output_dir}/correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_density_plots(df, output_dir):\n",
    "    # Kernel Density Estimation plots\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    measurements = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
    "    \n",
    "    for idx, measure in enumerate(measurements, 1):\n",
    "        plt.subplot(2, 2, idx)\n",
    "        for species in df['species'].unique():\n",
    "            subset = df[df['species'] == species]\n",
    "            sns.kdeplot(data=subset, x=measure, label=species)\n",
    "        plt.title(f'{measure} Distribution')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/density_plots.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def create_pair_plot(df, output_dir):\n",
    "    # Pair plot for all numeric variables\n",
    "    sns.pairplot(df, hue='species', diag_kind='kde')\n",
    "    plt.savefig(f'{output_dir}/pair_plot.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def create_island_distribution(df, output_dir):\n",
    "    # Stacked bar chart of species distribution by island\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    species_by_island = pd.crosstab(df['island'], df['species'])\n",
    "    species_by_island.plot(kind='bar', stacked=True)\n",
    "    plt.title('Species Distribution by Island')\n",
    "    plt.xlabel('Island')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Species')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}/island_distribution.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(args.input_file)\n",
    "    \n",
    "    # Create visualizations\n",
    "    create_species_comparison(df, args.output_dir)\n",
    "    create_interactive_scatter(df, args.output_dir)\n",
    "    create_correlation_heatmap(df, args.output_dir)\n",
    "    create_density_plots(df, args.output_dir)\n",
    "    create_pair_plot(df, args.output_dir)\n",
    "    create_island_distribution(df, args.output_dir)\n",
    "    \n",
    "    print(f\"Visualizations saved to {args.output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (non nextflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  FEMALE  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = \"data/penguins_size.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.921930</td>\n",
       "      <td>17.151170</td>\n",
       "      <td>200.915205</td>\n",
       "      <td>4201.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.459584</td>\n",
       "      <td>1.974793</td>\n",
       "      <td>14.061714</td>\n",
       "      <td>801.954536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.225000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.450000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "count      342.000000     342.000000         342.000000   342.000000\n",
       "mean        43.921930      17.151170         200.915205  4201.754386\n",
       "std          5.459584       1.974793          14.061714   801.954536\n",
       "min         32.100000      13.100000         172.000000  2700.000000\n",
       "25%         39.225000      15.600000         190.000000  3550.000000\n",
       "50%         44.450000      17.300000         197.000000  4050.000000\n",
       "75%         48.500000      18.700000         213.000000  4750.000000\n",
       "max         59.600000      21.500000         231.000000  6300.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the statistics of numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'species': ['Adelie' 'Chinstrap' 'Gentoo']\n",
      "Unique values in 'island': ['Torgersen' 'Biscoe' 'Dream']\n",
      "Unique values in 'sex': ['MALE' 'FEMALE' nan '.']\n"
     ]
    }
   ],
   "source": [
    "#Check the values of categorical features\n",
    "# Identify categorical columns (e.g., dtype == 'object' or 'category')\n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Display unique values for each categorical column\n",
    "for col in categorical_columns:\n",
    "    unique_values = df[col].unique()\n",
    "    print(f\"Unique values in '{col}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write channel with one item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bin/penguins.nf\n"
     ]
    }
   ],
   "source": [
    "%%writefile bin/penguins.nf\n",
    "#!/usr/bin/env nextflow\n",
    "\n",
    "params.data = '/home/zach/projects/psb2025-workshop/penguin_analysis/data/penguins_size.csv'\n",
    "params.cleaning_script = '/home/zach/projects/psb2025-workshop/penguin_analysis/bin/data_cleaning.py'\n",
    "params.analysis_script = '/home/zach/projects/psb2025-workshop/penguin_analysis/bin/species_analysis.py'\n",
    "\n",
    "process clean_data {\n",
    "    publishDir \"${launchDir}/data/\"\n",
    "    input:\n",
    "        path cleaning_script\n",
    "        path raw_input\n",
    "        \n",
    "    output:\n",
    "        path 'penguins_cleaned.csv'\n",
    "        \n",
    "    script:\n",
    "    \"\"\"\n",
    "    python  ${cleaning_script} --input_file ${raw_input}\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "process species_analysis {\n",
    "    publishDir \"${launchDir}/results/\"\n",
    "    input:\n",
    "        val species\n",
    "        path analysis_script\n",
    "        path cleaned_data\n",
    "        \n",
    "    output:\n",
    "        path \"${species}_basic_stats.csv\"\n",
    "        path \"${species}_correlations.png\"\n",
    "        path \"${species}_dimorphism_stats.csv\"\n",
    "        path \"${species}_distributions.png\"\n",
    "    \n",
    "    script:\n",
    "        \"\"\"\n",
    "        python ${analysis_script} --input_file ${cleaned_data} --species ${species} \n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "\n",
    "workflow {\n",
    "    // create a species channel\n",
    "    species_channel = Channel.from('Adelie', 'Gentoo', 'Chinstrap')\n",
    "    raw_data = \"${params.data}\"\n",
    "    \n",
    "    // clean the data\n",
    "    cleaning_script = \"${params.cleaning_script}\"\n",
    "    cleaned_data = clean_data(cleaning_script, raw_data)\n",
    "    \n",
    "    // run the analysis\n",
    "    analysis_script = \"${params.analysis_script}\"\n",
    "    species_analysis(species_channel, analysis_script, cleaned_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mNextflow 24.10.3 is available - Please consider updating your version to it\u001b[m\n",
      "\n",
      "\u001b[1m\u001b[38;5;232m\u001b[48;5;43m N E X T F L O W \u001b[0;2m  ~  \u001b[mversion 24.04.2\u001b[m\n",
      "\u001b[K\n",
      "Launching\u001b[35m `bin/penguins.nf` \u001b[0;2m[\u001b[0;1;36mdeadly_davinci\u001b[0;2m] DSL2 - \u001b[36mrevision: \u001b[0;36mc80f39d07f\u001b[m\n",
      "\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mclean_data       -\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mspecies_analysis -\u001b[K\n",
      "\u001b[3A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m87/4acf72\u001b[0;2m] \u001b[0;2m\u001b[mclean_data      \u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mspecies_analysis -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (1)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m87/4acf72\u001b[0;2m] \u001b[0;2m\u001b[mclean_data      \u001b[2m |\u001b[m 0 of 1\u001b[K\n",
      "\u001b[2m[\u001b[0;34m-        \u001b[0;2m] \u001b[0;2m\u001b[mspecies_analysis -\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (4)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m87/4acf72\u001b[0;2m] \u001b[0;2m\u001b[mclean_data          \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34mda/e898b6\u001b[0;2m] \u001b[0;2m\u001b[mspecies_analysis\u001b[33;2m (\u001b[0;33m3\u001b[2m)\u001b[m\u001b[2m |\u001b[m 0 of 3\u001b[K\n",
      "\u001b[4A\n",
      "\u001b[2mexecutor >  local (4)\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m87/4acf72\u001b[0;2m] \u001b[0;2m\u001b[mclean_data          \u001b[2m |\u001b[m 1 of 1\u001b[32m ✔\u001b[m\u001b[K\n",
      "\u001b[2m[\u001b[0;34m86/bd6ef2\u001b[0;2m] \u001b[0;2m\u001b[mspecies_analysis\u001b[33;2m (\u001b[0;33m2\u001b[2m)\u001b[m\u001b[2m |\u001b[m 3 of 3\u001b[32m ✔\u001b[m\u001b[K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! nextflow run bin/penguins.nf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
